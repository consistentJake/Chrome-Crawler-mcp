{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Jobs Interactive Filter\n",
    "\n",
    "This notebook provides an interactive UI to filter and explore OpenAI job postings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# ! pip install ipywidgets pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Set, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Job Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 147 jobs\n"
     ]
    }
   ],
   "source": [
    "# Load the extracted jobs data\n",
    "with open('all_jobs_extracted.json', 'r', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "jobs = raw_data['jobs']\n",
    "print(f\"Loaded {len(jobs)} jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Skills and Experience from Job Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_years_experience(text: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Extract years of experience requirement from text.\n",
    "    Returns the minimum years found, or None if not found.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # Patterns like \"5+ years\", \"3-5 years\", \"at least 4 years\"\n",
    "    patterns = [\n",
    "        r'(\\d+)\\+?\\s*(?:years?|yrs?)\\s+(?:of\\s+)?(?:professional\\s+)?(?:relevant\\s+)?(?:software\\s+)?(?:engineering\\s+)?experience',\n",
    "        r'(?:at\\s+least|minimum\\s+of?)\\s+(\\d+)\\s*(?:years?|yrs?)',\n",
    "        r'(\\d+)[-–](\\d+)\\s*(?:years?|yrs?)\\s+(?:of\\s+)?experience',\n",
    "        r'typically\\s+(\\d+)\\+?\\s*(?:years?|yrs?)',\n",
    "    ]\n",
    "    \n",
    "    years_found = []\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            if isinstance(match, tuple):\n",
    "                years_found.append(int(match[0]))\n",
    "            else:\n",
    "                years_found.append(int(match))\n",
    "    \n",
    "    return min(years_found) if years_found else None\n",
    "\n",
    "\n",
    "def extract_skills(text: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Extract skills and technologies mentioned in text.\n",
    "    Returns a set of skill names (lowercase).\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return set()\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    skills_found = set()\n",
    "    \n",
    "    # Define skill patterns with their canonical names\n",
    "    skill_patterns = {\n",
    "        # Programming Languages\n",
    "        'python': r'\\bpython\\b',\n",
    "        'go/golang': r'\\b(?:go|golang)\\b',\n",
    "        'rust': r'\\brust\\b',\n",
    "        'typescript': r'\\btypescript\\b',\n",
    "        'javascript': r'\\bjavascript\\b',\n",
    "        'java': r'\\bjava\\b(?!script)',\n",
    "        'c++': r'\\bc\\+\\+\\b',\n",
    "        'sql': r'\\bsql\\b',\n",
    "        'scala': r'\\bscala\\b',\n",
    "        'ruby': r'\\bruby\\b',\n",
    "        \n",
    "        # ML/AI\n",
    "        'machine learning': r'\\bmachine\\s+learning\\b',\n",
    "        'deep learning': r'\\bdeep\\s+learning\\b',\n",
    "        'llm': r'\\bllm(?:s)?\\b',\n",
    "        'nlp': r'\\bnlp\\b|\\bnatural\\s+language\\s+processing\\b',\n",
    "        'pytorch': r'\\bpytorch\\b',\n",
    "        'tensorflow': r'\\btensorflow\\b',\n",
    "        'reinforcement learning': r'\\breinforcement\\s+learning\\b',\n",
    "        'computer vision': r'\\bcomputer\\s+vision\\b',\n",
    "        \n",
    "        # Infrastructure/DevOps\n",
    "        'kubernetes': r'\\bkubernetes\\b|\\bk8s\\b',\n",
    "        'docker': r'\\bdocker\\b',\n",
    "        'aws': r'\\baws\\b|\\bamazon\\s+web\\s+services\\b',\n",
    "        'gcp': r'\\bgcp\\b|\\bgoogle\\s+cloud\\b',\n",
    "        'azure': r'\\bazure\\b',\n",
    "        'linux': r'\\blinux\\b',\n",
    "        'ci/cd': r'\\bci/?cd\\b',\n",
    "        'terraform': r'\\bterraform\\b',\n",
    "        \n",
    "        # Databases\n",
    "        'postgresql': r'\\bpostgres(?:ql)?\\b',\n",
    "        'mysql': r'\\bmysql\\b',\n",
    "        'mongodb': r'\\bmongodb\\b',\n",
    "        'redis': r'\\bredis\\b',\n",
    "        'elasticsearch': r'\\belasticsearch\\b',\n",
    "        \n",
    "        # Data Engineering\n",
    "        'spark': r'\\bspark\\b',\n",
    "        'kafka': r'\\bkafka\\b',\n",
    "        'airflow': r'\\bairflow\\b',\n",
    "        'data pipelines': r'\\bdata\\s+pipeline(?:s)?\\b',\n",
    "        'etl': r'\\betl\\b',\n",
    "        \n",
    "        # Web/API\n",
    "        'react': r'\\breact(?:\\.?js)?\\b',\n",
    "        'node.js': r'\\bnode(?:\\.?js)?\\b',\n",
    "        'fastapi': r'\\bfastapi\\b',\n",
    "        'graphql': r'\\bgraphql\\b',\n",
    "        'rest api': r'\\brest(?:ful)?\\s*api(?:s)?\\b',\n",
    "        \n",
    "        # Architecture/Concepts\n",
    "        'distributed systems': r'\\bdistributed\\s+systems?\\b',\n",
    "        'microservices': r'\\bmicroservices?\\b',\n",
    "        'system design': r'\\bsystem\\s+design\\b',\n",
    "        'backend': r'\\bbackend\\b|\\bback-end\\b',\n",
    "        'frontend': r'\\bfrontend\\b|\\bfront-end\\b',\n",
    "        'full-stack': r'\\bfull[-\\s]?stack\\b',\n",
    "        \n",
    "        # Soft Skills / Domains\n",
    "        'a/b testing': r'\\ba/?b\\s+test(?:ing)?\\b',\n",
    "        'data analysis': r'\\bdata\\s+analysis\\b',\n",
    "        'security': r'\\bsecurity\\b',\n",
    "        'networking': r'\\bnetworking\\b',\n",
    "    }\n",
    "    \n",
    "    for skill_name, pattern in skill_patterns.items():\n",
    "        if re.search(pattern, text_lower):\n",
    "            skills_found.add(skill_name)\n",
    "    \n",
    "    return skills_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 147 jobs\n",
      "\n",
      "Jobs with years experience data: 57\n",
      "Jobs with skills data: 123\n",
      "Jobs with compensation data: 133\n",
      "Jobs with location data: 146\n",
      "Unique locations: 8\n"
     ]
    }
   ],
   "source": [
    "# Process all jobs and extract structured data\n",
    "processed_jobs = []\n",
    "all_skills_counter = Counter()\n",
    "all_locations = set()\n",
    "\n",
    "for job in jobs:\n",
    "    extracted = job.get('extracted', {})\n",
    "    original = job.get('original_info', {})\n",
    "    \n",
    "    # Get text fields\n",
    "    about_role = extracted.get('about_the_role', '') or ''\n",
    "    you_might_thrive = extracted.get('you_might_thrive', [])\n",
    "    thrive_text = '\\n'.join(you_might_thrive) if isinstance(you_might_thrive, list) else (you_might_thrive or '')\n",
    "    combined_text = about_role + '\\n' + thrive_text\n",
    "    \n",
    "    # Extract skills\n",
    "    skills = extract_skills(combined_text)\n",
    "    for skill in skills:\n",
    "        all_skills_counter[skill] += 1\n",
    "    \n",
    "    # Extract years of experience\n",
    "    years_exp = extract_years_experience(combined_text)\n",
    "    \n",
    "    # Parse compensation\n",
    "    comp = extracted.get('compensation', '')\n",
    "    comp_min = None\n",
    "    if comp:\n",
    "        match = re.search(r'\\$(\\d+)K', comp)\n",
    "        if match:\n",
    "            comp_min = int(match.group(1))\n",
    "    \n",
    "    # Get locations (new field from updated extraction)\n",
    "    locations = extracted.get('location', [])\n",
    "    if isinstance(locations, str):\n",
    "        locations = [locations] if locations else []\n",
    "    for loc in locations:\n",
    "        all_locations.add(loc)\n",
    "    \n",
    "    # Get team from extracted (more accurate) or original\n",
    "    team = extracted.get('team') or original.get('team', 'Unknown')\n",
    "    \n",
    "    processed_jobs.append({\n",
    "        'title': extracted.get('title', original.get('title', 'Unknown')),\n",
    "        'team': team,\n",
    "        'url': original.get('url', ''),\n",
    "        'location': locations,  # New field\n",
    "        'compensation': comp,\n",
    "        'compensation_min_k': comp_min,\n",
    "        'years_experience': years_exp,\n",
    "        'skills': list(skills),\n",
    "        'about_the_role': about_role,\n",
    "        'you_might_thrive': thrive_text,\n",
    "        'about_the_team': extracted.get('about_the_team', ''),\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(processed_jobs)\n",
    "\n",
    "# Pre-compute search text columns for better performance\n",
    "df['_search_title'] = df['title'].fillna('').str.lower()\n",
    "df['_search_role'] = df['about_the_role'].fillna('').str.lower()\n",
    "df['_search_thrive'] = df['you_might_thrive'].fillna('').str.lower()\n",
    "df['_search_team'] = df['team'].fillna('').str.lower()\n",
    "df['_search_all'] = df['_search_title'] + ' ' + df['_search_role'] + ' ' + df['_search_thrive'] + ' ' + df['_search_team']\n",
    "df['_location_str'] = df['location'].apply(lambda x: ', '.join(x).lower() if x else '')\n",
    "\n",
    "ALL_LOCATIONS = sorted(list(all_locations))\n",
    "\n",
    "print(f\"Processed {len(df)} jobs\")\n",
    "print(f\"\\nJobs with years experience data: {df['years_experience'].notna().sum()}\")\n",
    "print(f\"Jobs with skills data: {(df['skills'].str.len() > 0).sum()}\")\n",
    "print(f\"Jobs with compensation data: {df['compensation'].notna().sum()}\")\n",
    "print(f\"Jobs with location data: {(df['location'].str.len() > 0).sum()}\")\n",
    "print(f\"Unique locations: {len(ALL_LOCATIONS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ALL EXTRACTED SKILLS (sorted by frequency)\n",
      "==================================================\n",
      "  python: 48 jobs\n",
      "  backend: 43 jobs\n",
      "  distributed systems: 42 jobs\n",
      "  security: 30 jobs\n",
      "  go/golang: 26 jobs\n",
      "  full-stack: 26 jobs\n",
      "  machine learning: 25 jobs\n",
      "  llm: 20 jobs\n",
      "  kubernetes: 19 jobs\n",
      "  data pipelines: 16 jobs\n",
      "  rust: 13 jobs\n",
      "  react: 13 jobs\n",
      "  postgresql: 11 jobs\n",
      "  javascript: 11 jobs\n",
      "  networking: 11 jobs\n",
      "  sql: 11 jobs\n",
      "  terraform: 11 jobs\n",
      "  typescript: 10 jobs\n",
      "  ci/cd: 10 jobs\n",
      "  linux: 9 jobs\n",
      "  frontend: 9 jobs\n",
      "  pytorch: 9 jobs\n",
      "  azure: 8 jobs\n",
      "  deep learning: 7 jobs\n",
      "  reinforcement learning: 7 jobs\n",
      "  mysql: 6 jobs\n",
      "  kafka: 6 jobs\n",
      "  data analysis: 5 jobs\n",
      "  java: 5 jobs\n",
      "  spark: 5 jobs\n",
      "  fastapi: 4 jobs\n",
      "  node.js: 4 jobs\n",
      "  tensorflow: 4 jobs\n",
      "  airflow: 2 jobs\n",
      "  a/b testing: 2 jobs\n",
      "  system design: 2 jobs\n",
      "  docker: 2 jobs\n",
      "  redis: 2 jobs\n",
      "  etl: 1 jobs\n",
      "  scala: 1 jobs\n",
      "  graphql: 1 jobs\n",
      "  gcp: 1 jobs\n",
      "  aws: 1 jobs\n",
      "\n",
      "Total unique skills: 43\n"
     ]
    }
   ],
   "source": [
    "# Display all extracted skills sorted by frequency\n",
    "print(\"=\" * 50)\n",
    "print(\"ALL EXTRACTED SKILLS (sorted by frequency)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "ALL_SKILLS = [skill for skill, _ in all_skills_counter.most_common()]\n",
    "\n",
    "for skill, count in all_skills_counter.most_common():\n",
    "    print(f\"  {skill}: {count} jobs\")\n",
    "\n",
    "print(f\"\\nTotal unique skills: {len(ALL_SKILLS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Job Filter UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobFilter:\n",
    "    \"\"\"\n",
    "    Interactive job filtering widget with optimized performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    MAX_DISPLAY_ROWS = 50  # Limit displayed rows for performance\n",
    "    \n",
    "    def __init__(self, dataframe: pd.DataFrame, all_skills: List[str], all_locations: List[str]):\n",
    "        self.df = dataframe\n",
    "        self.all_skills = all_skills\n",
    "        self.all_locations = all_locations\n",
    "        self.filtered_df = dataframe.copy()\n",
    "        \n",
    "        # Create widgets\n",
    "        self._create_widgets()\n",
    "        \n",
    "    def _create_widgets(self):\n",
    "        \"\"\"Create all filter widgets.\"\"\"\n",
    "        \n",
    "        # Keyword include filter\n",
    "        self.keyword_include = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='e.g., distributed, ML, backend',\n",
    "            description='Include:',\n",
    "            layout=widgets.Layout(width='500px'),\n",
    "            style={'description_width': '100px'}\n",
    "        )\n",
    "        \n",
    "        # Keyword exclude filter\n",
    "        self.keyword_exclude = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='e.g., manager, senior, lead',\n",
    "            description='Exclude:',\n",
    "            layout=widgets.Layout(width='500px'),\n",
    "            style={'description_width': '100px'}\n",
    "        )\n",
    "        \n",
    "        # Search in section selector\n",
    "        self.search_sections = widgets.SelectMultiple(\n",
    "            options=['Title', 'About Role', 'You Might Thrive', 'Team'],\n",
    "            value=['Title', 'About Role', 'You Might Thrive'],\n",
    "            description='Search in:',\n",
    "            layout=widgets.Layout(width='300px', height='100px'),\n",
    "            style={'description_width': '100px'}\n",
    "        )\n",
    "        \n",
    "        # Skills multi-select\n",
    "        self.skills_select = widgets.SelectMultiple(\n",
    "            options=self.all_skills,\n",
    "            value=[],\n",
    "            description='Skills:',\n",
    "            layout=widgets.Layout(width='300px', height='150px'),\n",
    "            style={'description_width': '100px'}\n",
    "        )\n",
    "        \n",
    "        # Skills match mode\n",
    "        self.skills_mode = widgets.RadioButtons(\n",
    "            options=['Any (OR)', 'All (AND)'],\n",
    "            value='Any (OR)',\n",
    "            description='Match:',\n",
    "            layout=widgets.Layout(width='200px'),\n",
    "            style={'description_width': '60px'}\n",
    "        )\n",
    "        \n",
    "        # Location filter (new)\n",
    "        self.location_select = widgets.SelectMultiple(\n",
    "            options=['All'] + self.all_locations,\n",
    "            value=['All'],\n",
    "            description='Location:',\n",
    "            layout=widgets.Layout(width='250px', height='100px'),\n",
    "            style={'description_width': '100px'}\n",
    "        )\n",
    "        \n",
    "        # Years of experience slider\n",
    "        self.years_exp = widgets.IntRangeSlider(\n",
    "            value=[0, 15],\n",
    "            min=0,\n",
    "            max=15,\n",
    "            step=1,\n",
    "            description='Years Exp:',\n",
    "            layout=widgets.Layout(width='400px'),\n",
    "            style={'description_width': '100px'}\n",
    "        )\n",
    "        \n",
    "        # Min compensation slider\n",
    "        self.min_comp = widgets.IntSlider(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=600,\n",
    "            step=10,\n",
    "            description='Min Comp (K):',\n",
    "            layout=widgets.Layout(width='400px'),\n",
    "            style={'description_width': '100px'}\n",
    "        )\n",
    "        \n",
    "        # Team filter\n",
    "        teams = ['All'] + sorted(self.df['team'].dropna().unique().tolist())\n",
    "        self.team_select = widgets.Dropdown(\n",
    "            options=teams,\n",
    "            value='All',\n",
    "            description='Team:',\n",
    "            layout=widgets.Layout(width='400px'),\n",
    "            style={'description_width': '100px'}\n",
    "        )\n",
    "        \n",
    "        # Apply button\n",
    "        self.apply_btn = widgets.Button(\n",
    "            description='Apply Filters',\n",
    "            button_style='primary',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        self.apply_btn.on_click(self._apply_filters)\n",
    "        \n",
    "        # Reset button\n",
    "        self.reset_btn = widgets.Button(\n",
    "            description='Reset',\n",
    "            button_style='warning',\n",
    "            layout=widgets.Layout(width='100px')\n",
    "        )\n",
    "        self.reset_btn.on_click(self._reset_filters)\n",
    "        \n",
    "        # Output area\n",
    "        self.output = widgets.Output()\n",
    "    \n",
    "    def _apply_filters(self, btn=None):\n",
    "        \"\"\"Apply all filters using vectorized operations for performance.\"\"\"\n",
    "        mask = pd.Series([True] * len(self.df), index=self.df.index)\n",
    "        \n",
    "        # Get filter values\n",
    "        include_keywords = [k.strip().lower() for k in self.keyword_include.value.split(',') if k.strip()]\n",
    "        exclude_keywords = [k.strip().lower() for k in self.keyword_exclude.value.split(',') if k.strip()]\n",
    "        sections = list(self.search_sections.value)\n",
    "        selected_skills = list(self.skills_select.value)\n",
    "        skills_mode = self.skills_mode.value\n",
    "        years_range = self.years_exp.value\n",
    "        min_comp = self.min_comp.value\n",
    "        team = self.team_select.value\n",
    "        selected_locations = [loc for loc in self.location_select.value if loc != 'All']\n",
    "        \n",
    "        # Build search column based on selected sections (vectorized)\n",
    "        search_cols = []\n",
    "        if 'Title' in sections:\n",
    "            search_cols.append('_search_title')\n",
    "        if 'About Role' in sections:\n",
    "            search_cols.append('_search_role')\n",
    "        if 'You Might Thrive' in sections:\n",
    "            search_cols.append('_search_thrive')\n",
    "        if 'Team' in sections:\n",
    "            search_cols.append('_search_team')\n",
    "        \n",
    "        if search_cols:\n",
    "            search_text = self.df[search_cols[0]].fillna('')\n",
    "            for col in search_cols[1:]:\n",
    "                search_text = search_text + ' ' + self.df[col].fillna('')\n",
    "        else:\n",
    "            search_text = self.df['_search_all']\n",
    "        \n",
    "        # Apply keyword include filter (vectorized)\n",
    "        if include_keywords:\n",
    "            include_mask = pd.Series([False] * len(self.df), index=self.df.index)\n",
    "            for kw in include_keywords:\n",
    "                include_mask = include_mask | search_text.str.contains(kw, na=False, regex=False)\n",
    "            mask = mask & include_mask\n",
    "        \n",
    "        # Apply keyword exclude filter (vectorized)\n",
    "        if exclude_keywords:\n",
    "            for kw in exclude_keywords:\n",
    "                mask = mask & ~search_text.str.contains(kw, na=False, regex=False)\n",
    "        \n",
    "        # Apply skills filter\n",
    "        if selected_skills:\n",
    "            if skills_mode == 'Any (OR)':\n",
    "                skills_mask = self.df['skills'].apply(lambda x: any(s in x for s in selected_skills))\n",
    "            else:  # All (AND)\n",
    "                skills_mask = self.df['skills'].apply(lambda x: all(s in x for s in selected_skills))\n",
    "            mask = mask & skills_mask\n",
    "        \n",
    "        # Apply location filter (new)\n",
    "        if selected_locations:\n",
    "            location_mask = self.df['location'].apply(\n",
    "                lambda x: any(loc in x for loc in selected_locations)\n",
    "            )\n",
    "            mask = mask & location_mask\n",
    "        \n",
    "        # Apply years experience filter (vectorized)\n",
    "        if years_range != (0, 15):\n",
    "            years_mask = (\n",
    "                self.df['years_experience'].isna() |\n",
    "                ((self.df['years_experience'] >= years_range[0]) & \n",
    "                 (self.df['years_experience'] <= years_range[1]))\n",
    "            )\n",
    "            mask = mask & years_mask\n",
    "        \n",
    "        # Apply compensation filter (vectorized)\n",
    "        if min_comp > 0:\n",
    "            comp_mask = (\n",
    "                self.df['compensation_min_k'].isna() |\n",
    "                (self.df['compensation_min_k'] >= min_comp)\n",
    "            )\n",
    "            mask = mask & comp_mask\n",
    "        \n",
    "        # Apply team filter\n",
    "        if team != 'All':\n",
    "            mask = mask & (self.df['team'] == team)\n",
    "        \n",
    "        self.filtered_df = self.df[mask]\n",
    "        self._display_results()\n",
    "    \n",
    "    def _reset_filters(self, btn=None):\n",
    "        \"\"\"Reset all filters.\"\"\"\n",
    "        self.keyword_include.value = ''\n",
    "        self.keyword_exclude.value = ''\n",
    "        self.search_sections.value = ['Title', 'About Role', 'You Might Thrive']\n",
    "        self.skills_select.value = []\n",
    "        self.skills_mode.value = 'Any (OR)'\n",
    "        self.location_select.value = ['All']\n",
    "        self.years_exp.value = (0, 15)\n",
    "        self.min_comp.value = 0\n",
    "        self.team_select.value = 'All'\n",
    "        self.filtered_df = self.df.copy()\n",
    "        self._display_results()\n",
    "    \n",
    "    def _display_results(self):\n",
    "        \"\"\"Display filtered results with pagination for performance.\"\"\"\n",
    "        with self.output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            n_results = len(self.filtered_df)\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"RESULTS: {n_results} jobs found\")\n",
    "            if n_results > self.MAX_DISPLAY_ROWS:\n",
    "                print(f\"(Showing first {self.MAX_DISPLAY_ROWS} results)\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            \n",
    "            if n_results == 0:\n",
    "                print(\"No jobs match your criteria. Try adjusting filters.\")\n",
    "                return\n",
    "            \n",
    "            # Limit display for performance\n",
    "            display_df = self.filtered_df.head(self.MAX_DISPLAY_ROWS)\n",
    "            \n",
    "            # Build HTML table efficiently\n",
    "            rows = []\n",
    "            for _, row in display_df.iterrows():\n",
    "                title = row['title'] or 'Unknown'\n",
    "                url = row['url'] or '#'\n",
    "                team = row['team'] or 'N/A'\n",
    "                locations = ', '.join(row['location']) if row['location'] else 'N/A'\n",
    "                comp = row['compensation'] or 'N/A'\n",
    "                years = row['years_experience']\n",
    "                years_str = f\"{int(years)}+ yrs\" if pd.notna(years) else 'N/A'\n",
    "                skills = ', '.join(row['skills'][:4]) + ('...' if len(row['skills']) > 4 else '') if row['skills'] else 'N/A'\n",
    "                \n",
    "                rows.append(f\"\"\"<tr>\n",
    "                    <td><a href=\"{url}\" target=\"_blank\">{title}</a></td>\n",
    "                    <td>{team}</td>\n",
    "                    <td>{locations}</td>\n",
    "                    <td>{comp}</td>\n",
    "                    <td>{years_str}</td>\n",
    "                    <td>{skills}</td>\n",
    "                </tr>\"\"\")\n",
    "            \n",
    "            html_table = f\"\"\"\n",
    "            <style>\n",
    "                .job-table {{ border-collapse: collapse; width: 100%; font-size: 12px; }}\n",
    "                .job-table th, .job-table td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "                .job-table th {{ background-color: #4CAF50; color: white; }}\n",
    "                .job-table tr:nth-child(even) {{ background-color: #f2f2f2; }}\n",
    "                .job-table tr:hover {{ background-color: #ddd; }}\n",
    "                .job-table a {{ color: #0066cc; text-decoration: none; }}\n",
    "                .job-table a:hover {{ text-decoration: underline; }}\n",
    "            </style>\n",
    "            <table class=\"job-table\">\n",
    "                <tr>\n",
    "                    <th>Title</th>\n",
    "                    <th>Team</th>\n",
    "                    <th>Location</th>\n",
    "                    <th>Compensation</th>\n",
    "                    <th>Years Exp</th>\n",
    "                    <th>Key Skills</th>\n",
    "                </tr>\n",
    "                {''.join(rows)}\n",
    "            </table>\n",
    "            \"\"\"\n",
    "            display(HTML(html_table))\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the complete filter UI.\"\"\"\n",
    "        # Header\n",
    "        header = widgets.HTML(\"<h2>OpenAI Jobs Filter</h2>\")\n",
    "        \n",
    "        # Keyword section\n",
    "        keyword_label = widgets.HTML(\"<b>Keyword Filters</b> (comma-separated):\")\n",
    "        keyword_box = widgets.VBox([\n",
    "            keyword_label,\n",
    "            self.keyword_include,\n",
    "            self.keyword_exclude,\n",
    "            self.search_sections\n",
    "        ])\n",
    "        \n",
    "        # Skills section\n",
    "        skills_label = widgets.HTML(\"<b>Skills Filter</b> (Ctrl/Cmd+Click for multiple):\")\n",
    "        skills_box = widgets.VBox([\n",
    "            skills_label,\n",
    "            widgets.HBox([self.skills_select, self.skills_mode])\n",
    "        ])\n",
    "        \n",
    "        # Location section (new)\n",
    "        location_label = widgets.HTML(\"<b>Location Filter</b>:\")\n",
    "        location_box = widgets.VBox([\n",
    "            location_label,\n",
    "            self.location_select\n",
    "        ])\n",
    "        \n",
    "        # Other filters\n",
    "        other_label = widgets.HTML(\"<b>Other Filters</b>:\")\n",
    "        other_box = widgets.VBox([\n",
    "            other_label,\n",
    "            self.team_select,\n",
    "            self.years_exp,\n",
    "            self.min_comp,\n",
    "        ])\n",
    "        \n",
    "        # Buttons\n",
    "        buttons = widgets.HBox([self.apply_btn, self.reset_btn])\n",
    "        \n",
    "        # Combine all - reorganized layout\n",
    "        top_row = widgets.HBox([keyword_box, skills_box, location_box], layout=widgets.Layout(gap='20px'))\n",
    "        \n",
    "        ui = widgets.VBox([\n",
    "            header,\n",
    "            top_row,\n",
    "            other_box,\n",
    "            buttons,\n",
    "            self.output\n",
    "        ], layout=widgets.Layout(padding='10px'))\n",
    "        \n",
    "        display(ui)\n",
    "        \n",
    "        # Show initial results\n",
    "        self._display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13211119fcc4c0b8d05f44dc616f9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>OpenAI Jobs Filter</h2>'), HBox(children=(VBox(children=(HTML(value='<b>Keyword…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and display the filter UI\n",
    "job_filter = JobFilter(df, ALL_SKILLS, ALL_LOCATIONS)\n",
    "job_filter.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Search Functions\n",
    "\n",
    "Use these helper functions for quick filtering without the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_jobs(\n",
    "    keywords: List[str] = None,\n",
    "    exclude: List[str] = None,\n",
    "    skills: List[str] = None,\n",
    "    locations: List[str] = None,\n",
    "    min_years: int = None,\n",
    "    max_years: int = None,\n",
    "    min_comp_k: int = None,\n",
    "    team: str = None,\n",
    "    skills_match_all: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Search jobs with various filters.\n",
    "    \n",
    "    Args:\n",
    "        keywords: List of keywords to match (any)\n",
    "        exclude: List of keywords to exclude\n",
    "        skills: List of skills to match\n",
    "        locations: List of locations to filter (any match)\n",
    "        min_years: Minimum years of experience\n",
    "        max_years: Maximum years of experience\n",
    "        min_comp_k: Minimum compensation in thousands\n",
    "        team: Team name to filter\n",
    "        skills_match_all: If True, match ALL skills; else ANY\n",
    "    \n",
    "    Returns:\n",
    "        Filtered DataFrame\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Use pre-computed search columns for performance\n",
    "    if keywords:\n",
    "        keywords_lower = [k.lower() for k in keywords]\n",
    "        mask = pd.Series([False] * len(result), index=result.index)\n",
    "        for kw in keywords_lower:\n",
    "            mask = mask | result['_search_all'].str.contains(kw, na=False, regex=False)\n",
    "        result = result[mask]\n",
    "    \n",
    "    if exclude:\n",
    "        exclude_lower = [k.lower() for k in exclude]\n",
    "        for kw in exclude_lower:\n",
    "            result = result[~result['_search_all'].str.contains(kw, na=False, regex=False)]\n",
    "    \n",
    "    if skills:\n",
    "        if skills_match_all:\n",
    "            result = result[result['skills'].apply(lambda x: all(s in x for s in skills))]\n",
    "        else:\n",
    "            result = result[result['skills'].apply(lambda x: any(s in x for s in skills))]\n",
    "    \n",
    "    if locations:\n",
    "        result = result[result['location'].apply(lambda x: any(loc in x for loc in locations))]\n",
    "    \n",
    "    if min_years is not None:\n",
    "        result = result[(result['years_experience'].isna()) | (result['years_experience'] >= min_years)]\n",
    "    \n",
    "    if max_years is not None:\n",
    "        result = result[(result['years_experience'].isna()) | (result['years_experience'] <= max_years)]\n",
    "    \n",
    "    if min_comp_k is not None:\n",
    "        result = result[(result['compensation_min_k'].isna()) | (result['compensation_min_k'] >= min_comp_k)]\n",
    "    \n",
    "    if team:\n",
    "        result = result[result['team'].str.contains(team, case=False, na=False)]\n",
    "    \n",
    "    return result[['title', 'team', 'location', 'compensation', 'years_experience', 'skills', 'url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Find Python backend jobs requiring 3-5 years experience\n",
    "results = search_jobs(\n",
    "    keywords=['backend'],\n",
    "    skills=['python'],\n",
    "    max_years=5\n",
    ")\n",
    "print(f\"Found {len(results)} jobs:\")\n",
    "results[['title', 'team', 'compensation', 'years_experience']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Find ML/AI jobs with compensation >= $300K, excluding manager roles\n",
    "results = search_jobs(\n",
    "    skills=['machine learning', 'deep learning'],\n",
    "    exclude=['manager', 'lead'],\n",
    "    min_comp_k=300\n",
    ")\n",
    "print(f\"Found {len(results)} jobs:\")\n",
    "results[['title', 'team', 'compensation', 'skills']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Find distributed systems jobs\n",
    "results = search_jobs(\n",
    "    skills=['distributed systems', 'kubernetes'],\n",
    "    skills_match_all=False  # Match ANY of these skills\n",
    ")\n",
    "print(f\"Found {len(results)} jobs:\")\n",
    "results[['title', 'team', 'compensation', 'skills']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View Job Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_job_details(title_contains: str):\n",
    "    \"\"\"\n",
    "    Show full details for a job matching the title.\n",
    "    \"\"\"\n",
    "    matches = df[df['title'].str.contains(title_contains, case=False)]\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        print(f\"No jobs found matching '{title_contains}'\")\n",
    "        return\n",
    "    \n",
    "    for _, job in matches.iterrows():\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"TITLE: {job['title']}\")\n",
    "        print(f\"TEAM: {job['team']}\")\n",
    "        print(f\"COMPENSATION: {job['compensation']}\")\n",
    "        print(f\"YEARS EXPERIENCE: {job['years_experience']}\")\n",
    "        print(f\"SKILLS: {', '.join(job['skills'])}\")\n",
    "        print(f\"URL: {job['url']}\")\n",
    "        print(\"\\n--- ABOUT THE ROLE ---\")\n",
    "        print(job['about_the_role'][:1000] + \"...\" if len(job['about_the_role']) > 1000 else job['about_the_role'])\n",
    "        print(\"\\n--- YOU MIGHT THRIVE ---\")\n",
    "        print(job['you_might_thrive'][:1000] + \"...\" if len(job['you_might_thrive']) > 1000 else job['you_might_thrive'])\n",
    "        print(\"=\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Show details for a specific job\n",
    "show_job_details(\"Research Engineer, Codex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistics and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compensation statistics\n",
    "print(\"=== COMPENSATION STATISTICS ===\")\n",
    "comp_df = df[df['compensation_min_k'].notna()]\n",
    "print(f\"Jobs with compensation data: {len(comp_df)}\")\n",
    "print(f\"Min: ${comp_df['compensation_min_k'].min()}K\")\n",
    "print(f\"Max: ${comp_df['compensation_min_k'].max()}K\")\n",
    "print(f\"Median: ${comp_df['compensation_min_k'].median()}K\")\n",
    "print(f\"Mean: ${comp_df['compensation_min_k'].mean():.0f}K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jobs by team\n",
    "print(\"=== JOBS BY TEAM ===\")\n",
    "team_counts = df['team'].value_counts()\n",
    "for team, count in team_counts.head(15).items():\n",
    "    print(f\"{team}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experience requirements distribution\n",
    "print(\"=== YEARS EXPERIENCE DISTRIBUTION ===\")\n",
    "years_counts = df['years_experience'].value_counts().sort_index()\n",
    "for years, count in years_counts.items():\n",
    "    if pd.notna(years):\n",
    "        print(f\"{int(years)}+ years: {count} jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
