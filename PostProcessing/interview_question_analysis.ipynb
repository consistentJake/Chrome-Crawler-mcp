{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interview Question Analysis\n",
    "\n",
    "Analyze common interview questions from extracted interview data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the extracted interviews data\n",
    "DATA_PATH = \"../output_20260127_014850/extracted_interviews_20260127_033819.json\"\n",
    "\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total groups: {len(data.get('extractions', []))}\")\n",
    "print(f\"Summary: {data.get('summary', {})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract All Question Topics from cross_post_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all 相关题目汇总 entries\n",
    "all_topics = []\n",
    "all_observations = []\n",
    "\n",
    "for group in data.get('extractions', []):\n",
    "    insights = group.get('cross_post_insights', {})\n",
    "    topics = insights.get('相关题目汇总', [])\n",
    "    observation = insights.get('综合观察', '')\n",
    "    \n",
    "    all_topics.extend(topics)\n",
    "    if observation:\n",
    "        all_observations.append(observation)\n",
    "\n",
    "print(f\"Total topic entries: {len(all_topics)}\")\n",
    "print(f\"Total observations: {len(all_observations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean and Normalize Topic Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_topic(topic: str) -> str:\n",
    "    \"\"\"Clean and normalize a topic string.\"\"\"\n",
    "    # Remove post references like （帖子3、4）\n",
    "    cleaned = re.sub(r'[（(][^）)]*帖子[^）)]*[）)]', '', topic)\n",
    "    # Remove trailing/leading whitespace\n",
    "    cleaned = cleaned.strip()\n",
    "    # Remove trailing punctuation\n",
    "    cleaned = cleaned.rstrip('：:')\n",
    "    return cleaned\n",
    "\n",
    "# Clean all topics\n",
    "cleaned_topics = [clean_topic(t) for t in all_topics if clean_topic(t)]\n",
    "print(f\"Cleaned topics: {len(cleaned_topics)}\")\n",
    "print(\"\\nSample cleaned topics:\")\n",
    "for t in cleaned_topics[:10]:\n",
    "    print(f\"  - {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Count Topic Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count exact matches\n",
    "topic_counter = Counter(cleaned_topics)\n",
    "\n",
    "print(\"Top 30 Most Common Topics (exact match):\")\n",
    "print(\"=\" * 60)\n",
    "for topic, count in topic_counter.most_common(30):\n",
    "    print(f\"{count:3d} | {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Group Similar Topics by Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keyword categories\n",
    "KEYWORD_CATEGORIES = {\n",
    "    \"System Design\": [\"system design\", \"系统设计\", \"SD\", \"Inference API\", \"distributed\", \"分布式\"],\n",
    "    \"In-memory DB/Cache\": [\"in-memory\", \"cache\", \"key-value\", \"KV\", \"DB\"],\n",
    "    \"LeetCode/Coding\": [\"leetcode\", \"coding\", \"算法\", \"backtrack\", \"dp\", \"bfs\", \"dfs\"],\n",
    "    \"ML/AI\": [\"ml\", \"machine learning\", \"rl\", \"reinforcement\", \"transformer\", \"attention\", \"llm\"],\n",
    "    \"Web/API\": [\"web\", \"api\", \"crawler\", \"http\", \"rest\"],\n",
    "    \"Take-home\": [\"take-home\", \"take home\", \"assignment\"],\n",
    "    \"BQ/Behavioral\": [\"bq\", \"behavioral\", \"行为\", \"culture\"],\n",
    "}\n",
    "\n",
    "def categorize_topic(topic: str) -> list:\n",
    "    \"\"\"Return all matching categories for a topic.\"\"\"\n",
    "    topic_lower = topic.lower()\n",
    "    categories = []\n",
    "    for category, keywords in KEYWORD_CATEGORIES.items():\n",
    "        for kw in keywords:\n",
    "            if kw.lower() in topic_lower:\n",
    "                categories.append(category)\n",
    "                break\n",
    "    return categories if categories else [\"Other\"]\n",
    "\n",
    "# Categorize all topics\n",
    "category_counter = Counter()\n",
    "category_topics = {}\n",
    "\n",
    "for topic in cleaned_topics:\n",
    "    cats = categorize_topic(topic)\n",
    "    for cat in cats:\n",
    "        category_counter[cat] += 1\n",
    "        if cat not in category_topics:\n",
    "            category_topics[cat] = []\n",
    "        category_topics[cat].append(topic)\n",
    "\n",
    "print(\"Topics by Category:\")\n",
    "print(\"=\" * 60)\n",
    "for cat, count in category_counter.most_common():\n",
    "    print(f\"{count:3d} | {cat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Question Descriptions from Individual Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract interview_info from all posts\n",
    "all_questions = []\n",
    "\n",
    "for group in data.get('extractions', []):\n",
    "    for post in group.get('posts', []):\n",
    "        interview_info = post.get('interview_info', {})\n",
    "        stage = post.get('interview_stage', '未知')\n",
    "        \n",
    "        # Skip filtered stages\n",
    "        if stage in ['未知', 'N/A', '无有效信息']:\n",
    "            continue\n",
    "        \n",
    "        question_type = interview_info.get('题目类型', '')\n",
    "        description = interview_info.get('题目描述', '')\n",
    "        requirements = interview_info.get('具体要求', [])\n",
    "        focus_areas = interview_info.get('考察重点', [])\n",
    "        \n",
    "        if description and description != '无有效信息' and description != 'N/A':\n",
    "            all_questions.append({\n",
    "                'stage': stage,\n",
    "                'type': question_type,\n",
    "                'description': description,\n",
    "                'requirements': requirements,\n",
    "                'focus_areas': focus_areas,\n",
    "                'url': post.get('source_url', ''),\n",
    "            })\n",
    "\n",
    "print(f\"Total valid question descriptions: {len(all_questions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count by question type\n",
    "type_counter = Counter(q['type'] for q in all_questions)\n",
    "\n",
    "print(\"Questions by Type:\")\n",
    "print(\"=\" * 60)\n",
    "for qtype, count in type_counter.most_common():\n",
    "    print(f\"{count:3d} | {qtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count by interview stage\n",
    "stage_counter = Counter(q['stage'] for q in all_questions)\n",
    "\n",
    "print(\"Questions by Interview Stage:\")\n",
    "print(\"=\" * 60)\n",
    "for stage, count in stage_counter.most_common(20):\n",
    "    print(f\"{count:3d} | {stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Find Common Question Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key patterns from descriptions\n",
    "COMMON_PATTERNS = [\n",
    "    (r'in-memory|key.?value|cache|db', 'In-Memory DB/Cache'),\n",
    "    (r'system design|sd|设计', 'System Design'),\n",
    "    (r'inference|api|middleware', 'Inference/API Design'),\n",
    "    (r'leetcode|lc|力扣', 'LeetCode'),\n",
    "    (r'crawler|爬虫', 'Web Crawler'),\n",
    "    (r'ml|machine learning|模型', 'ML/AI'),\n",
    "    (r'bq|behavioral|行为', 'Behavioral'),\n",
    "    (r'coding|code', 'Coding'),\n",
    "    (r'distributed|分布式', 'Distributed Systems'),\n",
    "    (r'chat|chatbox|聊天', 'Chat Service'),\n",
    "]\n",
    "\n",
    "pattern_counter = Counter()\n",
    "pattern_examples = {}\n",
    "\n",
    "for q in all_questions:\n",
    "    desc = q['description'].lower()\n",
    "    matched = False\n",
    "    for pattern, name in COMMON_PATTERNS:\n",
    "        if re.search(pattern, desc, re.IGNORECASE):\n",
    "            pattern_counter[name] += 1\n",
    "            if name not in pattern_examples:\n",
    "                pattern_examples[name] = []\n",
    "            if len(pattern_examples[name]) < 3:\n",
    "                pattern_examples[name].append(q['description'][:100])\n",
    "            matched = True\n",
    "            break\n",
    "    if not matched:\n",
    "        pattern_counter['Other'] += 1\n",
    "\n",
    "print(\"Common Question Patterns:\")\n",
    "print(\"=\" * 60)\n",
    "for pattern, count in pattern_counter.most_common():\n",
    "    print(f\"{count:3d} | {pattern}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples for each pattern\n",
    "print(\"Examples by Pattern:\")\n",
    "print(\"=\" * 80)\n",
    "for pattern, examples in pattern_examples.items():\n",
    "    print(f\"\\n### {pattern}\")\n",
    "    for i, ex in enumerate(examples, 1):\n",
    "        print(f\"  {i}. {ex}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detailed OA Questions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter OA-stage questions\n",
    "oa_questions = [q for q in all_questions if 'OA' in q['stage'].upper()]\n",
    "\n",
    "print(f\"Total OA questions: {len(oa_questions)}\")\n",
    "print(\"\\nOA Question Descriptions:\")\n",
    "print(\"=\" * 80)\n",
    "for i, q in enumerate(oa_questions[:20], 1):\n",
    "    print(f\"\\n{i}. [{q['type']}] {q['description'][:200]}\")\n",
    "    if q['requirements']:\n",
    "        print(f\"   Requirements: {', '.join(q['requirements'][:3])}\")\n",
    "    if q['focus_areas']:\n",
    "        print(f\"   Focus: {', '.join(q['focus_areas'][:3])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "summary = {\n",
    "    \"total_topics\": len(cleaned_topics),\n",
    "    \"total_questions\": len(all_questions),\n",
    "    \"top_topics\": topic_counter.most_common(20),\n",
    "    \"topics_by_category\": dict(category_counter),\n",
    "    \"questions_by_type\": dict(type_counter),\n",
    "    \"questions_by_stage\": dict(stage_counter.most_common(15)),\n",
    "    \"pattern_counts\": dict(pattern_counter),\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "output_path = \"interview_question_analysis_summary.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Summary saved to: {output_path}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
